# 23.1 | WebRTC

WebRTC (Web Real-Time Communication) is a powerful open-source technology that enables peer-to-peer (P2P) communication directly between web browsers and mobile applications without the need for plugins or external software. It supports real-time audio, video, and data transfer with minimal latency, making it ideal for a wide range of applications that require real-time interactions. Here's a deeper dive into WebRTC and its significance:

### Why WebRTC?

1. **Real-Time Media Communication:**
   - WebRTC is the only standardized protocol that allows browsers to communicate directly with each other, enabling real-time media (audio, video) and data exchange. This means you can establish a video call or data-sharing session between two parties with sub-second latency.
   - This real-time nature is crucial for applications like video conferencing, live streaming, gaming, and other use cases where low latency is essential.

2. **Peer-to-Peer (P2P) Connection:**
   - WebRTC establishes a direct P2P connection between clients, which helps in reducing latency since the media streams do not have to pass through a server, except for the signaling process. This not only minimizes delay but also decreases bandwidth costs as there is no need for media servers to manage the traffic.

3. **Cross-Platform and Cross-Browser:**
   - WebRTC is supported across major browsers like Chrome, Firefox, Edge, and Safari, ensuring compatibility on both desktop and mobile platforms. This makes it easier for developers to create real-time communication solutions that work consistently across different devices without installing plugins.

4. **Sub-Second Latency:**
   - For use cases such as video conferencing, remote control applications, or live gaming, latency is a critical factor. WebRTC provides sub-second latency, making it ideal for scenarios where immediate feedback is required. Traditional protocols like HTTP or WebSockets are not suitable for real-time media due to higher latency.

5. **Secure Communication:**
   - WebRTC uses SRTP (Secure Real-Time Transport Protocol) to ensure that audio and video data is encrypted during transmission. This guarantees that communication remains private and secure, which is essential for sensitive applications such as telehealth, finance, and confidential meetings.

### WebRTC Use Cases:

1. **Video Conferencing (Zoom/Google Meet) - Multi-Party Call:**
   - WebRTC is the backbone of popular video conferencing applications like Zoom and Google Meet. It allows multiple participants to join the same video call with real-time interaction. WebRTC’s ability to handle audio, video, and even data exchange makes it perfect for such platforms.
   - In a multi-party call, WebRTC can either establish direct peer connections (mesh architecture) or route media through a Selective Forwarding Unit (SFU), which optimizes bandwidth and connection stability for each participant.

2. **1:1 Video and Audio Calls (Omegle, Teaching Platforms):**
   - One-on-one video or audio calls are another common use case of WebRTC. Platforms like Omegle and online teaching tools rely on WebRTC to connect students and teachers or two random individuals directly in a seamless, real-time interaction.
   - The peer-to-peer nature of WebRTC makes these connections fast and efficient, with minimal server overhead.

3. **Real-Time Data Transfer (Gaming, Remote Desktop):**
   - Beyond media streaming, WebRTC can also transfer arbitrary data with minimal latency. This is especially useful for 30FPS online games or real-time applications like remote desktop sharing, where quick response times are vital.
   - WebRTC’s **Data Channels** feature enables the fast and efficient transmission of data, making it perfect for multiplayer games or collaborative tools where instant feedback is required.

4. **Streaming and Broadcasting (Live Sports, E-Learning, Concerts):**
   - WebRTC is also leveraged in applications that need to broadcast or stream content to large audiences, such as live sports events or concerts. While these platforms typically use a server to distribute the stream (due to the number of participants), WebRTC ensures the real-time nature of the transmission, with very low delay.

### Key Components of WebRTC:

1. **Media Streams:**
   - WebRTC handles media streams for audio and video, allowing developers to capture, process, and transmit these streams in real-time. The media stream can come from a local device (e.g., webcam or microphone) or an external source.

2. **Data Channels:**
   - WebRTC Data Channels allow developers to send arbitrary data between peers. These channels support low-latency, bidirectional, and reliable communication, making them suitable for real-time gaming, file sharing, chat messaging, or even synchronized collaboration tools.

3. **Signaling:**
   - WebRTC doesn’t specify a signaling protocol. Instead, it requires developers to use their own signaling mechanisms to exchange session information (SDP - Session Description Protocol) and network details. This process is usually handled by WebSockets, HTTP, or any other signaling protocol that suits the application.
   - Signaling is used to establish the initial connection between peers by exchanging media information and IP addresses, but after that, WebRTC works entirely peer-to-peer.

4. **NAT Traversal and STUN/TURN Servers:**
   - Since most devices are behind NAT (Network Address Translation) or firewalls, WebRTC uses STUN (Session Traversal Utilities for NAT) and TURN (Traversal Using Relays around NAT) servers to assist in connecting peers even in challenging network conditions.

### Advantages of WebRTC:

- **Low Latency:** Essential for real-time communication applications like gaming, remote meetings, or interactive streaming.
- **High Security:** End-to-end encryption ensures privacy and security for media and data transmission.
- **Cost Efficiency:** Peer-to-peer architecture reduces the need for heavy backend infrastructure and media servers.
- **Interoperability:** Works seamlessly across major browsers, making it ideal for cross-platform applications.
- **Scalability:** While direct P2P connections can handle limited participants, WebRTC can scale using SFUs for larger audiences, as seen in video conferencing solutions.

### Challenges with WebRTC:

1. **Scalability in Large Groups:**
   - For multi-party calls, handling many P2P connections can become inefficient. To manage this, developers often rely on SFUs or MCUs (Multipoint Control Units) that mix or selectively forward streams.
   
2. **Network Issues:**
   - NAT traversal and firewall issues can cause difficulty in establishing direct connections, though this is mitigated by STUN and TURN servers. TURN servers can relay data, but this adds latency and costs.

3. **Browser Support & Updates:**
   - While WebRTC is widely supported, different browsers may implement certain features differently, leading to compatibility issues that developers must handle.

### Conclusion:

WebRTC is a robust, secure, and efficient technology for building real-time communication applications. Whether it’s video conferencing, gaming, live streaming, or 1:1 calls, WebRTC is the go-to solution for applications requiring sub-second latency and P2P connectivity. Its native browser support, low latency, and ability to handle media and data streams make it an essential technology in today’s internet landscape.

Your comparison highlights the difference between **HLS (HTTP Live Streaming)** and **WebRTC** in terms of latency, which is critical based on the type of application.

### HLS (HTTP Live Streaming):
- **Latency: ~10 seconds**
- **Use Case: Streaming live events like sports (e.g., cricket matches), concerts, news broadcasts, etc.**
- **Why?** HLS is designed to deliver high-quality streams to large audiences with buffering to ensure a smooth viewing experience, even on unstable networks. It splits video into segments (typically 6-10 seconds) and streams them to the audience. The buffering adds latency but improves the overall stability and visual quality (no sudden drops in resolution or interruptions). For cricket matches and similar events, a slight delay (~10 seconds) is acceptable because viewers prioritize stream quality over real-time interaction.

### WebRTC (Web Real-Time Communication):
- **Latency: ~0.1 seconds (sub-second)**
- **Use Case: Real-time communication applications like Google Meet, Omegle, and interactive streaming (live gaming, remote control).**
- **Why?** WebRTC is optimized for minimal latency, crucial for real-time interactions. Whether it's a 1:1 call (e.g., Omegle) or a multi-party video conference (Google Meet), the focus is on reducing delay to near-zero for a smooth, interactive experience. The trade-off here is that WebRTC isn’t as focused on handling a large number of participants with prime visual quality, as the priority is immediate feedback and real-time communication.

### Summary:
- **HLS:** Best for scenarios like **cricket matches**, where a slight delay is acceptable in exchange for **high-quality streaming** to a broad audience.
- **WebRTC:** Best for scenarios like **video calls (Google Meet)** or **1:1 interactions (Omegle)**, where **real-time communication** is more critical than perfect visual quality.

**Understanding WebRTC Architecture and Terminology**

WebRTC (Web Real-Time Communication) is a technology that enables real-time communication directly between browsers and devices without the need for plugins or additional software. It allows for audio, video, and data sharing between peers, aiming for a seamless peer-to-peer (P2P) experience. Below is a breakdown of key concepts and components involved in WebRTC.

---

### **Peer-to-Peer (P2P) Communication**

WebRTC is designed to facilitate direct communication between two clients (peers) without relying on a central server to relay media. This direct connection minimizes latency and enhances performance.

**However**, establishing a direct P2P connection over the internet can be challenging due to network complexities like firewalls and NATs (Network Address Translators). To overcome these obstacles, additional components are utilized.

![P2P](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fd2ac1dd1-0dee-4a95-ac58-480952eddbe1%2FScreenshot_2024-05-04_at_4.08.18_PM.png?table=block&id=4c68439d-c7b4-48dc-a1de-6133761f63bb&cache=v2)
---

### **Signaling Server**

Before two peers can communicate, they need to exchange connection information—a process known as signaling. A signaling server facilitates this initial handshake by allowing peers to exchange:

- **Session control messages**
- **Network configurations**
- **Media capabilities**

The signaling server can use protocols like WebSockets or HTTP. It's important to note that WebRTC doesn't standardize signaling protocols; developers can choose the method that best fits their needs. Once the connection is established, the signaling server's role diminishes.
![Singnaling](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fc790a3de-337f-44a8-887a-64a207f7195c%2FScreenshot_2024-05-04_at_4.16.23_PM.png?table=block&id=7e2e3c43-dc21-45d9-88ef-d0648596f109&cache=v2)

---

### **STUN (Session Traversal Utilities for NAT) Server**

A STUN server helps a client discover its public-facing IP address and port, essentially revealing how it appears to the outside world. This information is crucial for setting up a direct connection between peers.

- **Function**: Determines the public IP and port by having the client send a request to the STUN server, which then replies with the information.
- **Use Case**: Helps in scenarios where peers are behind NATs or firewalls that modify or obscure their actual network addresses.

You can test STUN server responses using tools like [Trickle ICE](https://webrtc.github.io/samples/src/content/peerconnection/trickle-ice/).
![STUN](https://www.notion.so/image/https%3A%2F%2Fprod-files-secure.s3.us-west-2.amazonaws.com%2F085e8ad8-528e-47d7-8922-a23dc4016453%2Fac6c5d61-a704-4ff5-89e5-5d8d887082e1%2FScreenshot_2024-05-04_at_4.57.40_PM.png?table=block&id=d8b50e61-842c-41e2-857c-ef2753af011f&cache=v2)
---

### **ICE (Interactive Connectivity Establishment) Candidates**

ICE candidates are potential network addresses (IP and port combinations) that can be used to establish a connection between peers.

- **Types of ICE Candidates**:
  - **Host Candidates**: Direct IP addresses of the client.
  - **Server Reflexive Candidates**: Public IP addresses discovered via STUN servers.
  - **Relayed Candidates**: Addresses provided by TURN servers when direct connections are not possible.

**Purpose**: Peers exchange ICE candidates to find the most efficient path for communication, considering network constraints.

**Example**:
- Two peers on the same local network might use their private IP addresses.
- Peers in different countries would use their public IP addresses.

---

### **TURN (Traversal Using Relays around NAT) Server**

When direct P2P communication is blocked due to strict NATs or firewalls, a TURN server acts as a relay between peers.

- **Function**: Relays media between peers when direct connection isn't possible.
- **Impact**: Increases latency and bandwidth usage since all data passes through the TURN server.

**Use Case**: Essential for users on restrictive networks where incoming connections are blocked.

---

### **Offer and Answer Process**

The establishment of a WebRTC connection involves an exchange of session descriptions:

- **Offer**: The initiating peer sends its session description, including media capabilities and ICE candidates.
- **Answer**: The responding peer replies with its own session description and ICE candidates.

This exchange is essential for agreeing on communication parameters.

---

### **SDP (Session Description Protocol)**

SDP is a format for describing streaming media initialization parameters in an ASCII string. It includes:

- **Media Types**: Audio, video, etc.
- **Codecs and Encoding**: The protocols used to encode/decode media.
- **Network Details**: ICE candidates and other networking information.

**Example**:

```
v=0
o=- 423904492236154649 2 IN IP4 127.0.0.1
s=-
t=0 0
m=audio 49170 RTP/AVP 0
c=IN IP4 192.168.1.101
a=rtpmap:0 PCMU/8000
a=ice-options:trickle
a=candidate:1 1 UDP 2122260223 192.168.1.101 49170 typ host
...
```

---

### **RTCPeerConnection**

The `RTCPeerConnection` interface represents a connection between the local device and a remote peer. It handles:

- **Creating and Managing Offers/Answers**: Facilitates the SDP exchange.
- **ICE Candidate Management**: Gathers and processes ICE candidates.
- **Media Stream Handling**: Sends and receives audio, video, and data streams.

**Role**: Simplifies the complexity of WebRTC by providing a high-level API for developers.

**Reference**: [MDN Web Docs - RTCPeerConnection](https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection)

---

### **Summary**

Establishing a WebRTC connection involves several components working together:

1. **Signaling Server**: Used for initial handshake and exchanging session descriptions and ICE candidates.
2. **STUN Server**: Helps peers discover their public IP addresses for establishing direct connections.
3. **ICE Candidates**: Potential network endpoints exchanged between peers to find the optimal connection path.
4. **TURN Server**: Relays media when direct connections are blocked by network restrictions.
5. **SDP**: Describes media capabilities and network information in offers and answers.
6. **RTCPeerConnection**: Manages the WebRTC connection, handling signaling, ICE negotiation, and media exchange.

**Key Points**:

- A signaling server is necessary for initiating the connection but isn't involved once the connection is established.
- STUN servers are used to discover public IPs but don't relay media.
- TURN servers are used when peers can't connect directly, relaying media between them.
- Understanding these components is crucial for developing robust WebRTC applications.


**Establishing a WebRTC Connection Between Two Browsers**

To enable real-time communication between two browsers using WebRTC, you need to establish a peer-to-peer (P2P) connection and exchange media streams (audio/video). Below is a detailed step-by-step guide on how to connect the two sides and send media.

---

### **1. Initializing the Connection**

**Browser 1:**

1. **Create an `RTCPeerConnection` Instance**

   ```javascript
   const pc1 = new RTCPeerConnection();
   ```

   - **Purpose**: Initializes the WebRTC connection object that handles the signaling and media exchange.

2. **Create an Offer**

   ```javascript
   pc1.createOffer().then(offer => {
       // Proceed to set the local description
   });
   ```

   - **Purpose**: Generates an SDP (Session Description Protocol) offer containing media capabilities and network information.

3. **Set Local Description to the Offer**

   ```javascript
   pc1.setLocalDescription(offer).then(() => {
       // Send the offer to Browser 2
   });
   ```

   - **Purpose**: Updates the local session description with the offer.

4. **Send the Offer to Browser 2 via the Signaling Server**

   ```javascript
   signalingServer.send(JSON.stringify({ type: 'offer', sdp: offer.sdp }));
   ```

   - **Purpose**: Transmits the offer to the other peer using the signaling server (e.g., WebSocket, HTTP).

---

**Browser 2:**

5. **Receive the Offer from the Signaling Server**

   ```javascript
   signalingServer.onmessage = message => {
       const data = JSON.parse(message.data);
       if (data.type === 'offer') {
           // Proceed to set remote description
       }
   };
   ```

   - **Purpose**: Listens for incoming offers from Browser 1.

6. **Set Remote Description to the Offer**

   ```javascript
   pc2.setRemoteDescription(new RTCSessionDescription({ type: 'offer', sdp: data.sdp })).then(() => {
       // Create an answer
   });
   ```

   - **Purpose**: Updates the remote session description with the received offer.

7. **Create an Answer**

   ```javascript
   pc2.createAnswer().then(answer => {
       // Set local description to the answer
   });
   ```

   - **Purpose**: Generates an SDP answer containing Browser 2's capabilities.

8. **Set Local Description to the Answer**

   ```javascript
   pc2.setLocalDescription(answer).then(() => {
       // Send the answer back to Browser 1
   });
   ```

   - **Purpose**: Updates the local session description with the answer.

9. **Send the Answer to Browser 1 via the Signaling Server**

   ```javascript
   signalingServer.send(JSON.stringify({ type: 'answer', sdp: answer.sdp }));
   ```

   - **Purpose**: Sends the answer back to Browser 1 to complete the handshake.

---

**Browser 1:**

10. **Receive the Answer and Set Remote Description**

    ```javascript
    signalingServer.onmessage = message => {
        const data = JSON.parse(message.data);
        if (data.type === 'answer') {
            pc1.setRemoteDescription(new RTCSessionDescription({ type: 'answer', sdp: data.sdp }));
        }
    };
    ```

    - **Purpose**: Completes the initial connection setup by updating the remote session description.

---

### **2. Exchanging ICE Candidates**

To establish the best possible route for the P2P connection, both browsers need to exchange ICE candidates.

**Browser 1 and Browser 2:**

- **On ICE Candidate Event**

  ```javascript
  pc.onicecandidate = event => {
      if (event.candidate) {
          signalingServer.send(JSON.stringify({ type: 'candidate', candidate: event.candidate }));
      }
  };
  ```

  - **Purpose**: Sends newly discovered ICE candidates to the other peer.

- **Receive and Add ICE Candidates**

  ```javascript
  signalingServer.onmessage = message => {
      const data = JSON.parse(message.data);
      if (data.type === 'candidate' && data.candidate) {
          pc.addIceCandidate(new RTCIceCandidate(data.candidate));
      }
  };
  ```

  - **Purpose**: Adds received ICE candidates to the local `RTCPeerConnection` instance.

---

### **3. Sending Media Streams**

After establishing the P2P connection, you need to capture and send media streams.

**Both Browsers:**

1. **Request Camera and Microphone Access**

   ```javascript
   navigator.mediaDevices.getUserMedia({ audio: true, video: true })
       .then(stream => {
           // Proceed to add tracks
       })
       .catch(error => {
           console.error('Error accessing media devices.', error);
       });
   ```

   - **Purpose**: Obtains permission to use the user's camera and microphone.

2. **Add Media Tracks to `RTCPeerConnection`**

   ```javascript
   stream.getTracks().forEach(track => {
       pc.addTrack(track, stream);
   });
   ```

   - **Purpose**: Adds the media tracks to the connection so they can be sent to the remote peer.

3. **Handle Incoming Media Tracks**

   ```javascript
   pc.ontrack = event => {
       const [remoteStream] = event.streams;
       remoteVideoElement.srcObject = remoteStream;
   };
   ```

   - **Purpose**: Receives media tracks from the remote peer and plays them in a video element.

---

### **Complete Workflow Overview**

1. **Initialization**

   - Both browsers create `RTCPeerConnection` instances.
   - Browser 1 generates an offer and sends it to Browser 2.
   - Browser 2 receives the offer, sets the remote description, creates an answer, and sends it back.
   - Browser 1 receives the answer and sets the remote description.

2. **ICE Candidate Exchange**

   - Both browsers gather ICE candidates.
   - ICE candidates are exchanged via the signaling server.
   - Each browser adds the received ICE candidates to their `RTCPeerConnection` instances.

3. **Media Stream Handling**

   - Both browsers request media device access.
   - Media tracks are added to the `RTCPeerConnection`.
   - Incoming media tracks are received and rendered.

---

### **Key Code Snippets**

**Browser 1:**

```javascript
// Create RTCPeerConnection
const pc1 = new RTCPeerConnection();

// Handle ICE candidates
pc1.onicecandidate = event => {
    if (event.candidate) {
        signalingServer.send(JSON.stringify({ type: 'candidate', candidate: event.candidate }));
    }
};

// Create offer
pc1.createOffer()
    .then(offer => pc1.setLocalDescription(offer))
    .then(() => {
        signalingServer.send(JSON.stringify({ type: 'offer', sdp: pc1.localDescription.sdp }));
    });

// Receive answer
signalingServer.onmessage = message => {
    const data = JSON.parse(message.data);
    if (data.type === 'answer') {
        pc1.setRemoteDescription(new RTCSessionDescription({ type: 'answer', sdp: data.sdp }));
    } else if (data.type === 'candidate') {
        pc1.addIceCandidate(new RTCIceCandidate(data.candidate));
    }
};

// Get media and add tracks
navigator.mediaDevices.getUserMedia({ video: true, audio: true })
    .then(stream => {
        stream.getTracks().forEach(track => pc1.addTrack(track, stream));
    });
```

**Browser 2:**

```javascript
// Create RTCPeerConnection
const pc2 = new RTCPeerConnection();

// Handle ICE candidates
pc2.onicecandidate = event => {
    if (event.candidate) {
        signalingServer.send(JSON.stringify({ type: 'candidate', candidate: event.candidate }));
    }
};

// Receive offer
signalingServer.onmessage = message => {
    const data = JSON.parse(message.data);
    if (data.type === 'offer') {
        pc2.setRemoteDescription(new RTCSessionDescription({ type: 'offer', sdp: data.sdp }))
            .then(() => pc2.createAnswer())
            .then(answer => pc2.setLocalDescription(answer))
            .then(() => {
                signalingServer.send(JSON.stringify({ type: 'answer', sdp: pc2.localDescription.sdp }));
            });
    } else if (data.type === 'candidate') {
        pc2.addIceCandidate(new RTCIceCandidate(data.candidate));
    }
};

// Handle incoming tracks
const remoteVideoElement = document.getElementById('remoteVideo');
pc2.ontrack = event => {
    const [remoteStream] = event.streams;
    remoteVideoElement.srcObject = remoteStream;
};

// Get media and add tracks (if needed)
navigator.mediaDevices.getUserMedia({ video: true, audio: true })
    .then(stream => {
        stream.getTracks().forEach(track => pc2.addTrack(track, stream));
    });
```

---

### **Explanation of Key Components**

- **Signaling Server**: Facilitates the exchange of signaling messages (offer, answer, and ICE candidates) between peers. It is not involved in the media exchange.

- **RTCPeerConnection**: Represents a connection between the local device and a remote peer. It handles the negotiation and establishment of the connection.

- **ICE Candidates**: Network endpoints used for establishing a connection. They are exchanged to find the most efficient route.

- **SDP (Session Description Protocol)**: A format for describing streaming media initialization parameters. Used in the offer and answer.

- **Media Streams**: Audio and video data captured from the user's devices, sent over the established connection.

---

### **Handling Media Permissions and Streams**

1. **Request Permissions**

   - **Action**: Prompt the user to allow access to their camera and microphone.
   - **Note**: This is essential for privacy and security.

2. **Capture Media Streams**

   - **Action**: Use the `MediaStream` API to access the media data.
   - **Example**:

     ```javascript
     navigator.mediaDevices.getUserMedia({ video: true, audio: true })
         .then(stream => {
             // Use the stream
         });
     ```

3. **Add Media Tracks to Connection**

   - **Action**: Use `pc.addTrack()` to send media over the connection.
   - **Note**: Each track represents a media source (audio or video).

4. **Receive and Render Remote Media**

   - **Action**: Listen for `ontrack` events to receive media from the remote peer.
   - **Example**:

     ```javascript
     pc.ontrack = event => {
         const remoteStream = event.streams[0];
         videoElement.srcObject = remoteStream;
     };
     ```

---

### **Important Considerations**

- **Asynchronous Operations**: Many WebRTC methods return promises. Use `.then()` or `async/await` to handle them.

- **Error Handling**: Always include error handling for media access and connection issues.

  ```javascript
  .catch(error => {
      console.error('Error:', error);
  });
  ```

- **Browser Compatibility**: Ensure that the APIs used are supported by the target browsers.

- **Security**: WebRTC requires secure origins (`https` or `localhost`). Ensure your application is served over HTTPS.

---

### **Summary**

To establish a WebRTC connection and send media between two browsers:

1. **Set Up Signaling**

   - Use a signaling server to exchange offers, answers, and ICE candidates.

2. **Create Peer Connections**

   - Initialize `RTCPeerConnection` instances on both sides.

3. **Exchange Session Descriptions**

   - Browser 1 creates an offer and sends it to Browser 2.
   - Browser 2 creates an answer and sends it back.

4. **Exchange ICE Candidates**

   - Both browsers gather and exchange ICE candidates to establish the best connection path.

5. **Handle Media Streams**

   - Request permission to access media devices.
   - Capture media streams and add tracks to the connection.
   - Receive media tracks from the remote peer and render them.

By following these steps, you enable real-time, peer-to-peer communication with audio and video between browsers using WebRTC.

---

### **Additional Resources**

- **MDN Web Docs:**

  - [WebRTC API](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API)
  - [RTCPeerConnection](https://developer.mozilla.org/en-US/docs/Web/API/RTCPeerConnection)
  - [MediaDevices.getUserMedia()](https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia)

- **WebRTC Samples:**

  - [Simple Peer-to-Peer Connection](https://webrtc.github.io/samples/src/content/peerconnection/pc1/)
  - [Data Channels](https://webrtc.github.io/samples/src/content/datachannel/basic/)

- **WebRTC Tutorials:**

  - [WebRTC for the Curious](https://webrtcforthecurious.com/)
  - [Building a WebRTC Video Chat Application](https://www.tutorialspoint.com/webrtc/webrtc_video_chat_application.htm)

**Implementing a WebRTC Application with a Node.js Signaling Server and React Frontend**

In this guide, we'll build a WebRTC application that enables real-time communication between two browsers. We'll use:

- **Node.js** for the signaling server, implementing a WebSocket server that handles signaling messages.
- **React** for the frontend, managing the user interface and integrating the `RTCPeerConnection` object.

This implementation will support three types of signaling messages:

1. `createOffer`
2. `createAnswer`
3. `addIceCandidate`

We'll build upon the concepts discussed earlier and create a more comprehensive version of the example provided at [JSFiddle](https://jsfiddle.net/rainzhao/3L9sfsvf/).

---

## **Table of Contents**

1. [Overview](#overview)
2. [Setting Up the Signaling Server](#setting-up-the-signaling-server)
   - [Project Initialization](#project-initialization)
   - [Implementing the WebSocket Server](#implementing-the-websocket-server)
   - [Handling Signaling Messages](#handling-signaling-messages)
3. [Creating the React Frontend](#creating-the-react-frontend)
   - [Project Initialization](#frontend-project-initialization)
   - [Implementing the Peer Connection Logic](#implementing-the-peer-connection-logic)
   - [Handling User Interface](#handling-user-interface)
4. [Connecting the Pieces](#connecting-the-pieces)
5. [Testing the Application](#testing-the-application)
6. [Conclusion](#conclusion)
7. [Additional Resources](#additional-resources)

---

## **1. Overview**

We aim to:

- **Set up a signaling server** using Node.js and WebSocket.
- **Implement the client-side logic** in React, managing the `RTCPeerConnection` and media streams.
- **Exchange signaling messages** to establish a peer-to-peer connection.
- **Capture and send media streams** between the peers.

---

## **2. Setting Up the Signaling Server**

### **Project Initialization**

First, create a new Node.js project for your signaling server.

1. **Create a directory for the server:**

   ```bash
   mkdir signaling-server
   cd signaling-server
   ```

2. **Initialize a new Node.js project:**

   ```bash
   npm init -y
   ```

3. **Install the required dependencies:**

   We'll use the `ws` library for WebSocket support.

   ```bash
   npm install ws
   ```

### **Implementing the WebSocket Server**

Create a file named `server.js` in your project directory.

```javascript
// server.js

const WebSocket = require('ws');

const PORT = 3000;
const server = new WebSocket.Server({ port: PORT });

let clients = {};

server.on('connection', (socket) => {
  // Assign a unique ID to each connected client
  const id = generateUniqueId();
  clients[id] = socket;
  console.log(`Client ${id} connected`);

  socket.on('message', (message) => {
    handleMessage(id, message);
  });

  socket.on('close', () => {
    console.log(`Client ${id} disconnected`);
    delete clients[id];
  });
});

function handleMessage(senderId, message) {
  const data = JSON.parse(message);
  const { type, target, payload } = data;

  switch (type) {
    case 'createOffer':
    case 'createAnswer':
    case 'addIceCandidate':
      sendTo(target, {
        type,
        sender: senderId,
        payload,
      });
      break;
    default:
      console.error('Unknown message type:', type);
      break;
  }
}

function sendTo(targetId, message) {
  const targetSocket = clients[targetId];
  if (targetSocket) {
    targetSocket.send(JSON.stringify(message));
  } else {
    console.error(`Client ${targetId} does not exist`);
  }
}

function generateUniqueId() {
  return Math.random().toString(36).substr(2, 9);
}

console.log(`WebSocket signaling server is running on ws://localhost:${PORT}`);
```

**Explanation:**

- **Clients Management:** We maintain a `clients` object to keep track of connected clients and their WebSocket connections.
- **Message Handling:** The `handleMessage` function processes incoming messages and routes them to the appropriate client.
- **Unique IDs:** Each client is assigned a unique ID upon connection, used for routing messages.

### **Handling Signaling Messages**

Our signaling server supports three message types:

1. `createOffer`
2. `createAnswer`
3. `addIceCandidate`

Each message includes:

- **`type`**: The type of signaling message.
- **`target`**: The ID of the peer to whom the message is intended.
- **`payload`**: The actual data (SDP offer/answer or ICE candidate).
- **`sender`**: The ID of the sender (added by the server when forwarding messages).

**Example Message Structure:**

```json
{
  "type": "createOffer",
  "target": "peerId",
  "payload": {
    "sdp": "..."
  }
}
```

**Server Responsibilities:**

- **Forward Messages:** The server simply forwards messages between clients based on the `target` ID.
- **Error Handling:** If the target client doesn't exist, log an error.

---

## **3. Creating the React Frontend**

### **Frontend Project Initialization**

1. **Create a React app using Create React App:**

   ```bash
   npx create-react-app webrtc-app
   cd webrtc-app
   ```

2. **Install required dependencies:**

   We need a WebSocket client library. The browser's native `WebSocket` API suffices, but you can use libraries like `socket.io-client` if desired.

   For simplicity, we'll use the native `WebSocket` API.

### **Implementing the Peer Connection Logic**

**Create a React component named `App.js`:**

```javascript
// src/App.js

import React, { useRef, useState, useEffect } from 'react';

const SIGNALING_SERVER_URL = 'ws://localhost:3000';

function App() {
  const [clientId, setClientId] = useState('');
  const [targetId, setTargetId] = useState('');
  const [connected, setConnected] = useState(false);

  const localVideoRef = useRef(null);
  const remoteVideoRef = useRef(null);
  const pcRef = useRef(null);
  const socketRef = useRef(null);
  const localStreamRef = useRef(null);

  useEffect(() => {
    // Connect to the signaling server
    socketRef.current = new WebSocket(SIGNALING_SERVER_URL);

    socketRef.current.onopen = () => {
      console.log('Connected to the signaling server');
    };

    socketRef.current.onmessage = async (message) => {
      const data = JSON.parse(message.data);
      await handleSignalingData(data);
    };

    socketRef.current.onerror = (err) => {
      console.error('WebSocket error:', err);
    };

    return () => {
      socketRef.current.close();
    };
  }, []);

  const handleSignalingData = async (data) => {
    const { type, sender, payload } = data;

    switch (type) {
      case 'createOffer':
        await pcRef.current.setRemoteDescription(new RTCSessionDescription(payload));
        const answer = await pcRef.current.createAnswer();
        await pcRef.current.setLocalDescription(answer);
        sendMessage(sender, 'createAnswer', pcRef.current.localDescription);
        break;
      case 'createAnswer':
        await pcRef.current.setRemoteDescription(new RTCSessionDescription(payload));
        break;
      case 'addIceCandidate':
        if (payload) {
          try {
            await pcRef.current.addIceCandidate(new RTCIceCandidate(payload));
          } catch (err) {
            console.error('Error adding received ice candidate', err);
          }
        }
        break;
      default:
        console.error('Unknown message type:', type);
        break;
    }
  };

  const sendMessage = (target, type, payload) => {
    socketRef.current.send(
      JSON.stringify({
        type,
        target,
        payload,
      })
    );
  };

  const startConnection = async () => {
    // Create RTCPeerConnection
    pcRef.current = new RTCPeerConnection();

    // Handle ICE candidates
    pcRef.current.onicecandidate = (event) => {
      if (event.candidate) {
        sendMessage(targetId, 'addIceCandidate', event.candidate);
      }
    };

    // Handle remote stream
    pcRef.current.ontrack = (event) => {
      remoteVideoRef.current.srcObject = event.streams[0];
    };

    // Get local media
    try {
      const localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      localVideoRef.current.srcObject = localStream;
      localStreamRef.current = localStream;

      // Add tracks to peer connection
      localStream.getTracks().forEach((track) => {
        pcRef.current.addTrack(track, localStream);
      });

      if (connected) {
        // Create and send offer
        const offer = await pcRef.current.createOffer();
        await pcRef.current.setLocalDescription(offer);
        sendMessage(targetId, 'createOffer', pcRef.current.localDescription);
      }
    } catch (err) {
      console.error('Error accessing media devices.', err);
    }
  };

  const handleConnect = () => {
    if (!targetId) {
      alert('Please enter the target client ID.');
      return;
    }
    setConnected(true);
    startConnection();
  };

  return (
    <div>
      <h1>WebRTC Application</h1>
      <div>
        <label>
          Your Client ID:
          <input
            type="text"
            value={clientId}
            onChange={(e) => setClientId(e.target.value)}
            placeholder="Enter your client ID"
          />
        </label>
      </div>
      <div>
        <label>
          Target Client ID:
          <input
            type="text"
            value={targetId}
            onChange={(e) => setTargetId(e.target.value)}
            placeholder="Enter target client ID"
          />
        </label>
      </div>
      <button onClick={handleConnect} disabled={connected}>
        Connect
      </button>
      <div>
        <video ref={localVideoRef} autoPlay muted playsInline style={{ width: '45%', marginRight: '10%' }} />
        <video ref={remoteVideoRef} autoPlay playsInline style={{ width: '45%' }} />
      </div>
    </div>
  );
}

export default App;
```

**Explanation:**

- **State Variables:**
  - `clientId`: The ID of the current client (can be set manually or assigned by the server).
  - `targetId`: The ID of the peer we want to connect to.
  - `connected`: A flag indicating whether the connection has been initiated.
- **References:**
  - `localVideoRef` and `remoteVideoRef`: References to the video elements displaying local and remote streams.
  - `pcRef`: Reference to the `RTCPeerConnection` instance.
  - `socketRef`: Reference to the WebSocket connection.
  - `localStreamRef`: Reference to the local media stream.
- **WebSocket Connection:**
  - Connects to the signaling server and handles incoming messages.
- **Signaling Data Handling:**
  - Processes incoming signaling messages (`createOffer`, `createAnswer`, `addIceCandidate`).
- **Peer Connection Setup:**
  - Creates an `RTCPeerConnection`, handles ICE candidates, and remote streams.
- **Media Stream Handling:**
  - Obtains local media and adds tracks to the peer connection.
- **UI Elements:**
  - Input fields for client IDs and a button to initiate the connection.
  - Video elements to display local and remote streams.

### **Handling User Interface**

- **Client ID Management:**

  In a real application, the server would assign unique IDs to clients upon connection. For simplicity, we're allowing users to enter their own IDs.

- **Connecting to a Peer:**

  Users must enter the target client's ID to initiate a connection.

- **Video Display:**

  The local video is displayed on the left, and the remote video is displayed on the right.

---

## **4. Connecting the Pieces**

To make the application work, ensure that:

1. **Signaling Server is Running:**

   Start the signaling server by running:

   ```bash
   node server.js
   ```

2. **Frontend Application is Running:**

   Start the React app:

   ```bash
   npm start
   ```

3. **Access the Application in Multiple Browsers or Tabs:**

   - Open the application in two separate browser windows or tabs.
   - In each instance, set a unique client ID (e.g., `client1` and `client2`).
   - In each instance, set the target client ID to the other client's ID.

4. **Initiate the Connection:**

   - Click the **Connect** button in each instance.
   - The peers will exchange signaling messages via the signaling server.
   - Once connected, the local and remote video streams should display in each browser.

---

## **5. Testing the Application**

**Step-by-Step Testing:**

1. **Open Two Browser Instances:**

   - Browser A and Browser B.

2. **Set Client IDs:**

   - Browser A: Set `Your Client ID` to `clientA`.
   - Browser B: Set `Your Client ID` to `clientB`.

3. **Set Target IDs:**

   - Browser A: Set `Target Client ID` to `clientB`.
   - Browser B: Set `Target Client ID` to `clientA`.

4. **Connect:**

   - Click **Connect** on both browsers.

5. **Result:**

   - Both browsers should request camera and microphone permissions.
   - Once permissions are granted, local video streams appear.
   - The remote video from the other browser should also appear.

**Troubleshooting:**

- **ICE Candidate Exchange Issues:**

  - Ensure that both browsers can exchange ICE candidates.
  - Check for errors in the console related to ICE candidates.

- **Media Device Errors:**

  - Ensure that the browser has permission to access media devices.
  - Check for errors related to `getUserMedia`.

- **Signaling Server Connection:**

  - Verify that the signaling server is running and accessible.
  - Check for WebSocket connection errors.

---

## **6. Conclusion**

By following this guide, you've built a simple WebRTC application that:

- **Implements a signaling server** using Node.js and WebSocket.
- **Manages peer connections** and media streams on the frontend using React.
- **Facilitates real-time communication** between two browsers.

**Key Takeaways:**

- **Signaling Server:** Handles the exchange of signaling data but doesn't participate in media exchange.
- **RTCPeerConnection:** Manages the peer-to-peer connection and media streaming.
- **Media Streams:** Captured using `getUserMedia` and transmitted over the peer connection.
- **WebSockets:** Used for real-time signaling between clients.

---

## **7. Additional Resources**

- **WebRTC API Documentation:**
  - [MDN Web Docs - WebRTC API](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API)
  - [WebRTC Samples](https://webrtc.github.io/samples/)
- **React and WebRTC Tutorials:**
  - [Building a Video Chat App with React Hooks and WebRTC](https://blog.logrocket.com/webrtc-react-hooks/)
  - [Simple Peer-to-Peer Data Transfer with WebRTC and React](https://www.section.io/engineering-education/data-transfer-webrtc-react/)
- **WebSocket Libraries:**
  - [ws - a simple WebSocket library](https://github.com/websockets/ws)
- **Security Considerations:**
  - Ensure that your application is served over HTTPS in production, as `getUserMedia` and WebRTC require secure origins.

---

**Note:** This is a basic implementation intended for learning purposes. In a production environment, you should consider:

- **User Authentication:** Securely managing client identities.
- **Scalability:** Handling multiple connections and peers.
- **Error Handling and Reliability:** Implementing robust error handling and reconnection logic.
- **Security:** Encrypting signaling data and securing WebSocket connections.

---
**Enhancing the WebRTC Signaling Server for Bidirectional Communication and Multiple Rooms**

You've set up a basic WebSocket signaling server in TypeScript that facilitates one-way communication between two clients (sender and receiver). To enable both sides to send and receive media (bidirectional communication) and to support multiple rooms (allowing multiple pairs or groups of users to communicate separately), we'll need to modify the signaling server and adjust the client-side code accordingly.

---

## **Table of Contents**

1. [Understanding the Current Limitations](#understanding-the-current-limitations)
2. [Modifying the Signaling Server for Bidirectional Communication](#modifying-the-signaling-server-for-bidirectional-communication)
3. [Implementing Support for Multiple Rooms](#implementing-support-for-multiple-rooms)
4. [Complete Signaling Server Code](#complete-signaling-server-code)
5. [Adjusting the Client-Side Code](#adjusting-the-client-side-code)
6. [Testing the Enhanced Application](#testing-the-enhanced-application)
7. [Conclusion](#conclusion)
8. [Additional Resources](#additional-resources)

---

## **Understanding the Current Limitations**

**Current Server Capabilities:**

- Manages a single sender (`senderSocket`) and a single receiver (`receiverSocket`).
- Supports one-way communication: sender to receiver.
- Does not support multiple rooms or multiple pairs of users.

**Limitations:**

- **One-Way Communication:** Only one client can send media; the other can only receive.
- **Single Pair of Clients:** Only two clients can connect at a time.
- **No Room Management:** Cannot handle multiple independent connections simultaneously.

To overcome these limitations, we'll need to:

1. **Allow all connected clients to act as both sender and receiver.**
2. **Implement room management to support multiple pairs or groups of clients.**

---

## **Modifying the Signaling Server for Bidirectional Communication**

### **1. Managing Connected Clients**

Instead of having separate `senderSocket` and `receiverSocket` variables, we'll maintain a collection of connected clients.

```typescript
interface Client {
  id: string;
  socket: WebSocket;
  roomId?: string;
}

const clients: { [key: string]: Client } = {};
```

- **`clients` Object:** Stores all connected clients with their unique IDs.
- Each client can be associated with a `roomId` to identify the room they are in.

### **2. Assigning Unique IDs to Clients**

When a client connects, assign a unique identifier.

```typescript
import { v4 as uuidv4 } from 'uuid';

wss.on('connection', function connection(ws) {
  const clientId = uuidv4();
  clients[clientId] = { id: clientId, socket: ws };
  ws.send(JSON.stringify({ type: 'init', id: clientId }));
  
  // Handle messages and disconnections...
});
```

- **UUIDs:** Use the `uuid` library to generate unique IDs.
- **Initial Message:** Send the client their assigned ID upon connection.

### **3. Handling Messages for Bidirectional Communication**

Modify the message handler to route messages between clients based on room IDs and message types.

```typescript
ws.on('message', function message(data: any) {
  const message = JSON.parse(data);
  const client = clients[clientId];

  switch (message.type) {
    case 'join':
      // Client wants to join a room
      client.roomId = message.roomId;
      break;

    case 'offer':
    case 'answer':
    case 'iceCandidate':
      // Relay the message to other clients in the room
      broadcastToRoom(client.roomId, clientId, message);
      break;

    // Additional cases...
  }
});
```

### **4. Broadcasting Messages Within a Room**

Implement a function to send messages to all clients in the same room except the sender.

```typescript
function broadcastToRoom(roomId: string, senderId: string, message: any) {
  for (const id in clients) {
    const client = clients[id];
    if (client.roomId === roomId && client.id !== senderId) {
      client.socket.send(JSON.stringify({ ...message, senderId }));
    }
  }
}
```

- **Purpose:** Ensures that messages are sent to all other participants in the room.
- **Sender ID:** Included in the message to identify the source.

---

## **Implementing Support for Multiple Rooms**

### **1. Room Management**

Clients can create or join rooms by specifying a `roomId`.

- **Creating/Joining a Room:**

  ```typescript
  case 'join':
    client.roomId = message.roomId;
    ws.send(JSON.stringify({ type: 'joined', roomId: client.roomId }));
    break;
  ```

- **Clients specify the room they want to join by sending a `join` message with a `roomId`.

### **2. Updating Message Handling**

Ensure that messages are only broadcasted to clients within the same room.

- **Modify `broadcastToRoom`:** Already implemented to send messages within the same room.

- **Message Types to Handle:**

  - `offer`
  - `answer`
  - `iceCandidate`

- **Example:**

  ```typescript
  case 'offer':
    broadcastToRoom(client.roomId, clientId, {
      type: 'offer',
      sdp: message.sdp,
    });
    break;
  ```

### **3. Handling Disconnections**

When a client disconnects, remove them from the `clients` object.

```typescript
ws.on('close', () => {
  delete clients[clientId];
  console.log(`Client disconnected: ${clientId}`);
});
```

---

## **Complete Signaling Server Code**

Below is the updated server code incorporating bidirectional communication and multiple rooms.

```typescript
// src/index.ts

import { WebSocket, WebSocketServer } from 'ws';
import { v4 as uuidv4 } from 'uuid';

interface Client {
  id: string;
  socket: WebSocket;
  roomId?: string;
}

const wss = new WebSocketServer({ port: 8080 });
const clients: { [key: string]: Client } = {};

wss.on('connection', function connection(ws) {
  const clientId = uuidv4();
  clients[clientId] = { id: clientId, socket: ws };
  console.log(`Client connected: ${clientId}`);

  ws.send(JSON.stringify({ type: 'init', id: clientId }));

  ws.on('message', function message(data: any) {
    const message = JSON.parse(data);
    const client = clients[clientId];

    switch (message.type) {
      case 'join':
        client.roomId = message.roomId;
        ws.send(JSON.stringify({ type: 'joined', roomId: client.roomId }));
        console.log(`Client ${clientId} joined room ${client.roomId}`);
        break;

      case 'offer':
      case 'answer':
      case 'iceCandidate':
        broadcastToRoom(client.roomId, clientId, {
          type: message.type,
          sdp: message.sdp,
          candidate: message.candidate,
        });
        break;

      default:
        console.error('Unknown message type:', message.type);
        break;
    }
  });

  ws.on('close', () => {
    delete clients[clientId];
    console.log(`Client disconnected: ${clientId}`);
  });

  ws.on('error', console.error);
});

function broadcastToRoom(roomId: string | undefined, senderId: string, message: any) {
  if (!roomId) return;
  for (const id in clients) {
    const client = clients[id];
    if (client.roomId === roomId && client.id !== senderId) {
      client.socket.send(JSON.stringify({ ...message, senderId }));
    }
  }
}

console.log('WebSocket signaling server is running on ws://localhost:8080');
```

---

## **Adjusting the Client-Side Code**

To work with the updated signaling server, the client code needs to:

1. **Connect to the Signaling Server and Receive Client ID**
2. **Join a Room**
3. **Handle Incoming Messages Appropriately**
4. **Initiate Peer Connection and Media Exchange**

### **1. Connecting to the Signaling Server**

Update the client code to store the assigned `clientId`.

```javascript
socket.onmessage = async (event) => {
  const data = JSON.parse(event.data);
  switch (data.type) {
    case 'init':
      clientId = data.id;
      console.log('Assigned client ID:', clientId);
      break;
    // Handle other message types...
  }
};
```

### **2. Joining a Room**

Allow the user to specify a `roomId` and send a `join` message.

```javascript
function joinRoom(roomId) {
  socket.send(JSON.stringify({ type: 'join', roomId }));
}
```

- **User Interface:** Add an input field for the `roomId`.

### **3. Handling Signaling Messages**

Update the message handler to process messages with dynamic sender IDs.

```javascript
socket.onmessage = async (event) => {
  const data = JSON.parse(event.data);
  const { type, senderId, sdp, candidate } = data;

  switch (type) {
    case 'joined':
      console.log(`Joined room: ${data.roomId}`);
      // Maybe initiate a call
      break;
    case 'offer':
      await pc.setRemoteDescription(new RTCSessionDescription(sdp));
      const answer = await pc.createAnswer();
      await pc.setLocalDescription(answer);
      socket.send(JSON.stringify({ type: 'answer', sdp: pc.localDescription, targetId: senderId }));
      break;
    case 'answer':
      await pc.setRemoteDescription(new RTCSessionDescription(sdp));
      break;
    case 'iceCandidate':
      if (candidate) {
        await pc.addIceCandidate(new RTCIceCandidate(candidate));
      }
      break;
    // Other cases...
  }
};
```

- **Note:** Include `targetId` when sending messages to specify the recipient.

### **4. Initiating Peer Connection and Media Exchange**

Adjust the code to:

- Create an `RTCPeerConnection` instance.
- Handle ICE candidates.
- Add media tracks.
- Exchange offers and answers as needed.

**Example:**

```javascript
// Create RTCPeerConnection
const pc = new RTCPeerConnection();

// Handle ICE candidates
pc.onicecandidate = (event) => {
  if (event.candidate) {
    socket.send(
      JSON.stringify({
        type: 'iceCandidate',
        candidate: event.candidate,
      })
    );
  }
};

// Handle incoming tracks
pc.ontrack = (event) => {
  remoteVideo.srcObject = event.streams[0];
};

// Get local media and add tracks
navigator.mediaDevices.getUserMedia({ video: true, audio: true }).then((stream) => {
  localVideo.srcObject = stream;
  stream.getTracks().forEach((track) => {
    pc.addTrack(track, stream);
  });
});
```

**Initiate Call:**

When a user joins a room, they can initiate a call by creating an offer.

```javascript
function initiateCall() {
  pc.createOffer().then((offer) => {
    pc.setLocalDescription(offer);
    socket.send(JSON.stringify({ type: 'offer', sdp: offer }));
  });
}
```

---

## **Testing the Enhanced Application**

**Setup:**

1. **Run the Signaling Server:**

   ```bash
   tsc -b
   node dist/index.js
   ```

2. **Start the Client Application:**

   Ensure that the client code is updated and running.

**Testing Steps:**

1. **Open Multiple Browser Tabs or Windows:**

   - Client A
   - Client B
   - (Optional) Client C, etc.

2. **Connect to the Signaling Server:**

   - Each client should receive a unique `clientId`.

3. **Join a Common Room:**

   - All clients enter the same `roomId` (e.g., `room123`).

4. **Initiate Calls:**

   - Any client can initiate a call by creating an offer.
   - Other clients in the room will receive the offer and respond with an answer.

5. **Exchange Media:**

   - All clients should be able to send and receive media streams with others in the room.

**Expected Outcome:**

- **Bidirectional Communication:** All clients in the same room can communicate with each other.
- **Multiple Rooms:** Clients in different rooms do not interfere with each other's communication.
- **Scalability:** The server can handle multiple rooms and clients simultaneously.

---

## **Conclusion**

By modifying the signaling server and client code, we've achieved:

- **Bidirectional Communication:** Both sides can send and receive media.
- **Multiple Room Support:** Clients can join different rooms, allowing multiple independent communication sessions.

**Key Enhancements:**

- **Client Management:** Keeping track of connected clients and their room associations.
- **Dynamic Message Routing:** Broadcasting messages within rooms and handling multiple message types.
- **Room Management:** Enabling clients to create and join rooms.

**Next Steps:**

- **Enhance Error Handling:** Add robust error handling and validation.
- **Implement User Interface Improvements:** Allow users to select rooms and manage calls more intuitively.
- **Security Considerations:** Implement authentication and secure the signaling server.

---

## **Additional Resources**

- **GitHub Repository for Reference:**

  - [hkirat/omegle](https://github.com/hkirat/omegle/): An example of a WebRTC application with signaling server supporting multiple rooms.

- **WebRTC Documentation:**

  - [MDN Web Docs - WebRTC API](https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API)
  - [WebRTC Samples](https://webrtc.github.io/samples/)

- **TypeScript and WebSocket Libraries:**

  - [ws - WebSocket Library for Node.js](https://github.com/websockets/ws)
  - [uuid - For Generating Unique IDs](https://github.com/uuidjs/uuid)

