## What is Kubernetes?

Kubernetes, often abbreviated as k8s, is an open-source container orchestration platform that automates many of the manual processes involved in deploying, managing, and scaling containerized applications. It is particularly useful for managing applications that are composed of multiple containers that need to communicate with each other.

#### Key Features of Kubernetes:
1. **Deployment**: Automates the deployment of containerized applications, ensuring they are distributed correctly across the cluster.
2. **Scaling**: Automatically scales applications up or down based on demand.
3. **Healing**: Automatically replaces or reschedules containers that fail, ensuring high availability.
4. **Configuration Management**: Manages application configuration separately from the code, enabling updates without redeploying the entire application.
5. **Resource Optimization**: Efficiently uses resources, ensuring that containers are running on the most suitable nodes.
6. **Monitoring and Logging**: Provides insights into the health and performance of applications through integrated monitoring and logging.


### Benefits of Using Kubernetes:
1. **Automated Deployment and Scaling**: You can easily deploy and scale your applications without manual intervention.
2. **Self-Healing**: Kubernetes automatically restarts failed containers, replaces them, and reschedules them when nodes die.
3. **Easy Rollouts and Rollbacks**: Manage updates to your applications with simple commands and automatically roll back if something goes wrong.
4. **Service Discovery and Load Balancing**: Automatically discovers services and load balances traffic across containers.
5. **Storage Orchestration**: Automatically mounts the storage system of your choice, whether from local storage, a public cloud provider, or a network storage system.

### How Kubernetes Helps:
- **Cloud-Native Deployment**: Ensures that your Docker images can be deployed in a cloud-native manner.
- **System Reliability**: Minimizes the need to worry about patching and crashes as Kubernetes handles auto-healing.
- **Scalability**: Offers easy auto-scaling with simple constructs.
- **Observability**: Provides a comprehensive dashboard for observing the entire system.

### Conclusion

Kubernetes simplifies the management of containerized applications by providing robust features for deployment, scaling, monitoring, and maintenance. It is particularly well-suited for cloud-native applications where high availability, scalability, and efficiency are critical.

The missing word in the statement "Kubernetes is also known as k8s. K_ _ _ _ _ _ _ _ s" is "Kubernetes".
Here is a comparison table outlining the differences between deployment before Kubernetes and after Kubernetes:

| Aspect                   | Before Kubernetes                                                                                              | After Kubernetes                                                                                         |
|--------------------------|----------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|
| **Infrastructure Setup** | Manual setup and configuration of individual EC2 instances for frontend and backend.                          | Automated orchestration and deployment of containers using Kubernetes.                                   |
| **Load Balancing**       | Use of a load balancer to distribute traffic across multiple backend EC2 instances.                           | In-built load balancing and service discovery provided by Kubernetes.                                     |
| **Deployment**           | Manual deployment of applications to each instance.                                                           | Automated deployment of containers using Kubernetes Deployments and ReplicaSets.                          |
| **Scaling**              | Manual scaling by adding/removing EC2 instances.                                                              | Automatic scaling using Horizontal Pod Autoscaler (HPA).                                                  |
| **Monitoring**           | Use of external tools for monitoring and health checks.                                                       | Integrated monitoring and health checks through Kubernetes API server and kubelet.                        |
| **Fault Tolerance**      | Limited fault tolerance, requiring manual intervention to restart failed instances.                           | Built-in self-healing capabilities with automatic container restarts and rescheduling.                    |
| **Configuration Management** | Manual management of configuration across multiple instances.                                           | Centralized configuration management using ConfigMaps and Secrets.                                        |
| **Resource Utilization** | Fixed allocation of resources to EC2 instances, potentially leading to underutilization or over-provisioning. | Efficient resource utilization through dynamic scheduling and resource requests/limits.                    |
| **Updates and Rollbacks** | Manual process to update applications and roll back if needed.                                             | Seamless updates and rollbacks using Kubernetes rolling updates and rollback features.                     |
| **Networking**           | Configuration of networking rules manually.                                                                  | Simplified networking with Kubernetes Service, Ingress, and kube-proxy for internal and external traffic. |


In the "After Kubernetes" deployment, the infrastructure is more resilient, scalable, and easier to manage, with Kubernetes handling much of the complexity involved in container orchestration.


### Benefits of Moving to Kubernetes
1. **Scalability**: Kubernetes can automatically scale the number of container instances based on traffic load.
2. **Self-Healing**: Kubernetes automatically restarts failed containers, ensuring high availability.
3. **Deployment Management**: Easier management of application updates and rollbacks.
4. **Resource Efficiency**: Kubernetes efficiently manages resources across the cluster, optimizing the use of CPU and memory.
5. **Service Discovery and Load Balancing**: Built-in mechanisms for service discovery and load balancing.
6. **Observability**: Comprehensive monitoring and logging capabilities integrated within the Kubernetes ecosystem.

Transitioning to Kubernetes would enhance the efficiency, reliability, and scalability of the application by leveraging these advanced features.

### Kubernetes Architecture After Migration

After migrating to Kubernetes, the architecture becomes more robust and flexible. Below is an explanation of the key components and their roles in this new setup, along with the required references to official documentation and concepts.

### High-Level Diagram of Kubernetes Architecture

1. **Nodes**:
   - In Kubernetes, a collection of machines (physical or virtual) form a cluster, where each machine is known as a node. There are two types of nodes:
     - **Master Node (Control Plane)**: Manages the Kubernetes cluster.
     - **Worker Nodes**: Run the containerized applications.

### Master Node (Control Plane)

- **API Server**:
  - Handles RESTful API requests from clients (kubectl, other Kubernetes components, external applications).
  - Manages authentication and authorization of API requests.
  - Exposes metrics and health check endpoints.
  - Acts as the central communication hub for the control plane.
  - [Kubernetes API Server](https://kubernetes.io/docs/concepts/overview/components/#kube-apiserver)

- **etcd**:
  - A consistent and highly available key-value store used as Kubernetes' backing store for all cluster data.
  - [etcd Quickstart](https://etcd.io/docs/v3.5/quickstart/)

- **kube-scheduler**:
  - Watches for newly created Pods with no assigned node and selects a node for them to run on.
  - [Kubernetes Scheduler](https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/)

- **kube-controller-manager**:
  - Runs a set of controllers responsible for managing various aspects of the cluster's state.
  - Examples of controllers:
    - **Node Controller**: Monitors and responds when nodes go down.
    - **Deployment Controller**: Manages the creation and updating of ReplicaSets.
    - **ReplicaSet Controller**: Ensures the desired number of pod replicas are running.
  - [Kube-Controller-Manager](https://kubernetes.io/docs/concepts/architecture/controller/)

### Worker Nodes

- These nodes run the actual applications (frontend and backend services).

### Diagram Explanation with Notion Image Jargon

Here's a conceptual diagram depicting the Kubernetes architecture, representing both the control plane and worker nodes:

![Kubernetes Architecture](https://notion-image-url)

1. **Control Plane Components**:
   - **API Server**: Central hub for communication and API requests.
   - **etcd**: Distributed key-value store.
   - **Scheduler**: Assigns pods to nodes.
   - **Controller Manager**: Manages controllers ensuring the desired state.

2. **Worker Nodes**:
   - Run pods that host frontend and backend applications.

### Transition Benefits

1. **Scalability**: Kubernetes automatically manages the scaling of applications based on traffic and load.
2. **High Availability**: Self-healing capabilities ensure applications remain available despite node failures.
3. **Efficient Resource Utilization**: Optimizes the use of resources across the cluster.
4. **Simplified Deployment and Management**: Streamlines the deployment process and management of application updates and rollbacks.
5. **Observability and Monitoring**: Integrated tools for monitoring and logging enhance visibility into application performance and health.

### Conclusion

Migrating to Kubernetes enhances the flexibility, scalability, and reliability of your application infrastructure. By leveraging the robust features of Kubernetes, you can efficiently manage your containerized applications, ensuring high availability and optimal performance.

### Kubernetes Architecture Overview

#### Nodes

In Kubernetes, a cluster consists of multiple machines (nodes) connected together, each running Kubernetes. Nodes are categorized into two types:

1. **Master Node (Control Plane)**
   - Manages the entire cluster.
   - Deploys and monitors containers.
   - Ensures the system is self-healing.
   - Listens to instructions from developers.

2. **Worker Nodes**
   - Run the actual applications (containers/pods).
   - Handle the application workloads.

#### Master Node (Control Plane) Components

1. **API Server**
   - **Handling RESTful API Requests**: Processes requests from clients (e.g., kubectl, other Kubernetes components, external applications).
     - Creates, reads, updates, and deletes Kubernetes resources (pods, services, deployments).
   - **Authentication and Authorization**: Ensures only authenticated and authorized users/components can perform actions.
     - Validates user credentials and checks access control policies.
   - **Metrics and Health Checks**: Exposes endpoints for monitoring the health and performance of the control plane.
   - **Communication Hub**: Central communication point for the control plane.
     - Interacts with other components (scheduler, controller manager, kubelet) to manage the cluster state.

2. **etcd**
   - A consistent and highly available key-value store for all cluster data.
   - Stores configuration data, state information, and metadata.
   - [etcd Quickstart](https://etcd.io/docs/v3.5/quickstart/)

3. **kube-scheduler**
   - Monitors for newly created pods with no assigned node.
   - Assigns nodes to these pods based on resource availability and constraints.
   - [Kubernetes Scheduler](https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/)

4. **kube-controller-manager**
   - Runs a set of controllers that manage the state of the cluster.
   - Ensures the desired state matches the current state by making necessary adjustments.
   - [Kube-Controller-Manager](https://kubernetes.io/docs/concepts/architecture/controller/)

   **Examples of Controllers**:
   - **Node Controller**: Detects and responds when nodes go down.
   - **Deployment Controller**: Manages deployments and ensures desired state by creating/updating ReplicaSets.
   - **ReplicaSet Controller**: Ensures the desired number of pod replicas are running, creating/deleting pods as necessary.

### Worker Nodes

Worker nodes are responsible for running the applications. Each worker node contains:

- **Kubelet**: An agent that ensures the containers are running in a pod.
- **Kube-proxy**: A network proxy that runs on each node, maintaining network rules for communication with the pods.
- **Container Runtime**: Software responsible for running containers (e.g., Docker, containerd).

### Benefits of Kubernetes

1. **Scalability**: Automatically scales applications based on traffic.
2. **High Availability**: Self-healing capabilities ensure uptime.
3. **Efficient Resource Utilization**: Optimizes resource usage across the cluster.
4. **Simplified Deployment and Management**: Streamlines deployment and management of applications.
5. **Observability and Monitoring**: Integrated tools for monitoring and logging.

### Summary

By adopting Kubernetes, the infrastructure becomes more robust, scalable, and easier to manage. Kubernetes automates many aspects of application deployment and management, providing a powerful platform for running containerized applications.

### Kubernetes Architecture Overview (Continued)

#### Worker Nodes

Worker nodes are responsible for running the actual application workloads, including both backend and frontend services. Each worker node consists of several critical components:

1. **kubelet**

   The kubelet is an essential agent running on each node in the Kubernetes cluster. Its primary responsibilities include:
   
   - **Watch for PodSpecs**: The kubelet monitors the API server for PodSpecs scheduled to run on its node. This involves managing new pods that need to be started, as well as updating or terminating existing pods.
   
   - **Reconcile Desired State**: The kubelet compares the current state of the node (running pods and their statuses) with the desired state as defined by the PodSpecs.
   
   - **Take Action**: To align the actual state with the desired state, the kubelet performs several actions:
     - **Start Pods**: Pulls necessary container images, creates containers, and starts the pods.
     - **Monitor Health**: Conducts health checks (liveness and readiness probes) on running containers. Containers failing health checks may be restarted based on the pod's restart policy.
     - **Update Pods**: Updates running pods in response to changes in PodSpecs (e.g., configuration updates).
     - **Stop Pods**: Terminates and removes containers when pods are no longer needed or must be terminated.
     
   - **Report Status**: Periodically reports the status of pods and the node back to the API server, including resource usage (CPU, memory) and container statuses.

2. **kube-proxy**

   The kube-proxy is a network proxy running on each node in the Kubernetes cluster. Its functions include:
   
   - **Network Routing**: Manages network rules for communication between services and pods.
   - **Service Discovery**: Enables communication within the cluster by maintaining network rules and facilitating service discovery.

3. **Container Runtime**

   The container runtime is the software responsible for running containers on a worker node. It interacts with the kubelet to manage the lifecycle of containers as specified by Kubernetes pod specifications.

   Common container runtimes used in Kubernetes include:
   
   - **containerd**: A high-level container runtime designed for simplicity and portability.
   - **CRI-O**: An implementation of the Kubernetes Container Runtime Interface (CRI) to enable using the Open Container Initiative (OCI) runtime.
   - **Docker**: A popular container runtime used for creating and managing containers.
   
   **Kubernetes Container Runtime Interface (CRI)**: 
   
   The CRI is a plugin interface that allows the kubelet to use various container runtimes without needing to know the specifics of each runtime. This abstraction layer provides flexibility and choice to users by enabling Kubernetes to support multiple container runtimes.

### Summary of Kubernetes Components

- **Nodes**: Machines in the Kubernetes cluster (Master and Worker nodes).
- **Master Node (Control Plane)**: Manages the cluster (API Server, etcd, kube-scheduler, kube-controller-manager).
- **Worker Nodes**: Run application workloads (kubelet, kube-proxy, container runtime).

By leveraging these components, Kubernetes provides a robust and flexible platform for deploying, managing, and scaling containerized applications.

### Cluster
A Kubernetes cluster consists of a collection of worker nodes and master nodes. You can add or remove nodes from a cluster as needed to scale the infrastructure.

### Images
A Docker image is a lightweight, standalone, and executable software package that includes everything needed to run a piece of software: code, runtime, libraries, environment variables, and configuration files. Images are built from a set of instructions defined in a Dockerfile.

Example: [MongoDB Docker Image](https://hub.docker.com/_/mongo)

### Containers
A container is an instance of an image in execution. For example, to run a PostgreSQL container, you would use the following command:
```sh
docker run -p 5432:5432 -e POSTGRES_PASSWORD=mysecretpassword -d postgres
```

### Pods
A pod is the smallest and simplest unit in the Kubernetes object model that you can create or deploy. A pod represents a single instance of a running process in your cluster.

### Cluster
A Kubernetes cluster consists of a collection of worker nodes and master nodes. You can add or remove nodes from a cluster as needed to scale the infrastructure.

### Images
A Docker image is a lightweight, standalone, and executable software package that includes everything needed to run a piece of software: code, runtime, libraries, environment variables, and configuration files. Images are built from a set of instructions defined in a Dockerfile.

Example: [MongoDB Docker Image](https://hub.docker.com/_/mongo)

### Containers
A container is an instance of an image in execution. For example, to run a PostgreSQL container, you would use the following command:
```sh
docker run -p 5432:5432 -e POSTGRES_PASSWORD=mysecretpassword -d postgres
```

### Pods
A pod is the smallest and simplest unit in the Kubernetes object model that you can create or deploy. A pod represents a single instance of a running process in your cluster.
Sure, here's the information structured and cleaned up, with a more organized format:

### Creating a Kubernetes (K8s) Cluster

#### Locally (Ensure You Have Docker Installed)
##### Using Kind

1. **Install Kind**
   Follow the instructions here: [Kind Installation Guide](https://kind.sigs.k8s.io/docs/user/quick-start/#installation)

2. **Single Node Setup**
   - **Create a 1-node cluster:**
     ```sh
     kind create cluster --name local
     ```
   - **Check Docker containers running:**
     ```sh
     docker ps
     ```
     You will notice a single container running (control-plane).
   - **Delete the cluster:**
     ```sh
     kind delete cluster --name local
     ```

3. **Multi-node Setup**
   - **Create a `clusters.yml` file:**
     ```yaml
     kind: Cluster
     apiVersion: kind.x-k8s.io/v1alpha4
     nodes:
     - role: control-plane
     - role: worker
     - role: worker
     ```
   - **Create the node setup:**
     ```sh
     kind create cluster --config clusters.yml --name local
     ```
   - **Check Docker containers:**
     ```sh
     docker ps
     ```

   Now, you have a multi-node cluster running locally.

##### Using Minikube

1. **Install Minikube**
   Follow the instructions here: [Minikube Installation Guide](https://minikube.sigs.k8s.io/docs/start/?arch=%2Fmacos%2Fx86-64%2Fstable%2Fbinary+download)

2. **Start a K8s cluster locally:**
   ```sh
   minikube start
   ```
3. **Check Docker containers:**
   ```sh
   docker ps
   ```
   This will show a single node setup. Note: A single node setup is functional but not ideal for production as you don't want your control plane to run containers or act as a worker.

#### On Cloud
##### Google Kubernetes Engine (GKE)
1. **Install Google Cloud SDK**
   Follow the instructions here: [Google Cloud SDK Installation](https://cloud.google.com/sdk/docs/install)

2. **Create a GKE cluster:**
   ```sh
   gcloud container clusters create my-cluster --num-nodes=3
   ```

3. **Get authentication credentials for the cluster:**
   ```sh
   gcloud container clusters get-credentials my-cluster
   ```

##### AWS Kubernetes Service (EKS)
1. **Install AWS CLI and eksctl**
   Follow the instructions here: [AWS CLI Installation](https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html) and [eksctl Installation](https://eksctl.io/introduction/#installation)

2. **Create an EKS cluster:**
   ```sh
   eksctl create cluster --name my-cluster --nodes 3
   ```

3. **Update kubeconfig for the cluster:**
   ```sh
   aws eks update-kubeconfig --name my-cluster
   ```

##### Vultr Kubernetes Engine
1. **Sign up for Vultr and create a Kubernetes cluster through their platform UI.**
   [Vultr Kubernetes Engine](https://www.vultr.com/products/kubernetes/)

2. **Follow the provided instructions to configure `kubectl` for accessing your Vultr cluster.**

### Diagram (Notion Image)
- **Cluster**: Includes all nodes
- **Nodes**: Comprise worker and master (control plane)
- **Pods**: The smallest deployable units in Kubernetes
- **Containers**: Running instances of Docker images
- **Images**: Base for containers

### Summary
- **Kind**: Suitable for local multi-node setups using Docker.
- **Minikube**: Ideal for starting a local single-node Kubernetes cluster quickly.
- **GKE, EKS, Vultr**: Cloud options for scalable Kubernetes clusters.

Each tool has its use case, with local tools (Kind, Minikube) being ideal for development and testing, while cloud providers (GKE, EKS, Vultr) offer robust solutions for production environments.

