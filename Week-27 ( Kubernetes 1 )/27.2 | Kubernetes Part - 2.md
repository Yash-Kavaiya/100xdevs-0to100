# 27.2 | Kubernetes Part - 2

## Deployment 
A Deployment in Kubernetes is a higher-level abstraction that manages a set of Pods and provides declarative updates to them. It offers features like scaling, rolling updates, and rollback capabilities, making it easier to manage the lifecycle of applications.

- Pod: A Pod is the smallest and simplest Kubernetes object. It represents a single instance of a running process in your cluster, typically containing one or more containers.
- Deployment: A Deployment is a higher-level controller that manages a set of identical Pods. It ensures the desired number of Pods are running and provides declarative updates to the Pods it manages.

In Kubernetes, understanding the distinction between Pods and Deployments is crucial for efficient application management. Here is a concise comparison to highlight the key differences:

### Abstraction Level
- **Pod**: 
  - The smallest and simplest Kubernetes object.
  - Represents a single instance of a running process in the cluster.
  - Typically contains one or more tightly coupled containers.

- **Deployment**:
  - A higher-level controller.
  - Manages a set of identical Pods.
  - Ensures the desired number of Pods are running.

### Management
- **Pod**:
  - Ephemeral and can be created and destroyed frequently.
  - Managed manually unless part of a higher-level controller.

- **Deployment**:
  - Ensures the specified number of Pod replicas are running.
  - Automatically replaces failed Pods.
  - Provides lifecycle management for applications.

### Updates
- **Pod**:
  - Requires manual intervention for updates.
  - Direct updates can lead to downtime.

- **Deployment**:
  - Supports rolling updates.
  - Allows gradual rollout of changes, e.g., updating the container image.
  - Can roll back to a previous version if something goes wrong.

### Scaling
- **Pod**:
  - Manual scaling involves creating or deleting individual Pods.

- **Deployment**:
  - Easy scaling by specifying the desired number of replicas.
  - The Deployment controller adjusts the number of Pods automatically.

### Self-Healing
- **Pod**:
  - Needs manual restart if it crashes, unless managed by a Deployment.

- **Deployment**:
  - Automatically replaces failed Pods.
  - Ensures the desired state is always maintained.

### Summary
- **Pod**: The fundamental unit of execution in Kubernetes, representing a single instance of a process.
- **Deployment**: A powerful controller that manages Pods, ensuring high availability, easy updates, scaling, and self-healing capabilities.

By leveraging Deployments, you can achieve greater resilience, easier management, and more seamless updates for your applications running on Kubernetes.

A ReplicaSet in Kubernetes plays a critical role in maintaining the desired number of pod replicas. Here's an in-depth look at what a ReplicaSet is and how it relates to Deployments and Pods:

### ReplicaSet Overview

A **ReplicaSet** is a Kubernetes controller that ensures a specified number of pod replicas are running at any given time. Its primary purpose is to maintain a stable set of replica Pods running in the cluster, even if some Pods fail or are deleted.

### Key Features of ReplicaSet

1. **Maintaining Desired State**:
   - Ensures that a specified number of replicas are always running.
   - If a Pod fails or is deleted, the ReplicaSet automatically creates a new Pod to replace it.

2. **Selector**:
   - Uses a selector to identify the Pods it should manage.
   - The selector matches the labels specified in the Pod template.

### Relationship Between ReplicaSet, Deployment, and Pods

- **Pod**:
  - The smallest and simplest Kubernetes object representing a single instance of a running process.

- **ReplicaSet**:
  - Ensures a specified number of identical Pods are running.
  - Maintains the desired number of replicas through its lifecycle.

- **Deployment**:
  - A higher-level controller that manages ReplicaSets.
  - When you create a Deployment, you specify the number of replicas.
  - The Deployment controller creates and manages a ReplicaSet, which in turn creates the specified number of Pods.

### How Deployments Use ReplicaSets

- When you create a Deployment, you specify the number of replicas and provide a Pod template.
- The Deployment creates a ReplicaSet based on the Pod template.
- The ReplicaSet ensures that the desired number of Pods are running, even if some Pods fail or are deleted.
- The Deployment controller manages the ReplicaSet and handles updates, rollbacks, and scaling.

### Key Differences Between ReplicaSet and Deployment

- **Abstraction Level**:
  - **ReplicaSet**: Focuses on maintaining the desired number of Pod replicas.
  - **Deployment**: A higher-level abstraction that manages ReplicaSets and provides additional features such as rolling updates and rollbacks.

- **Updates**:
  - **ReplicaSet**: Does not directly support rolling updates or rollbacks.
  - **Deployment**: Supports rolling updates and rollbacks, making it easier to manage application lifecycle and updates.

- **Scaling**:
  - **ReplicaSet**: Manually scaled by changing the number of replicas.
  - **Deployment**: Allows easy scaling by adjusting the number of replicas in the Deployment specification.

### Example YAML for Deployment and ReplicaSet

**Deployment YAML**:
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: example-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      containers:
      - name: example-container
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

**ReplicaSet YAML** (usually managed by the Deployment, shown here for illustration):
```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: example-replicaset
  labels:
    app: example
spec:
  replicas: 3
  selector:
    matchLabels:
      app: example
  template:
    metadata:
      labels:
        app: example
    spec:
      containers:
      - name: example-container
        image: nginx:1.14.2
        ports:
        - containerPort: 80
```

### Summary

- **ReplicaSet**: Ensures a stable set of Pod replicas. It is primarily responsible for maintaining the desired number of Pods.
- **Deployment**: Manages ReplicaSets and provides advanced features like rolling updates, rollbacks, and easy scaling. When you create a Deployment, it creates and manages a ReplicaSet, which in turn manages the Pods.

Using Deployments to manage ReplicaSets simplifies the process of maintaining applications, allowing for easy updates, scaling, and maintaining high availability.

### Series of Events in Kubernetes

Here's a detailed sequence of events when a user creates a Deployment, and how the ReplicaSet and Pods are managed:

1. **User Creates a Deployment**:
   - The user defines and submits a Deployment YAML to the Kubernetes API server.
   - The Deployment specification includes the desired number of replicas, the Pod template, and other configurations.

2. **Deployment Controller Creates a ReplicaSet**:
   - The Kubernetes Deployment controller receives the request and processes the Deployment object.
   - The Deployment controller creates a ReplicaSet based on the Pod template specified in the Deployment.
   - The ReplicaSet inherits the specifications such as the number of replicas, labels, and Pod template from the Deployment.

3. **ReplicaSet Creates Pods**:
   - The ReplicaSet controller ensures that the specified number of Pods are running.
   - It creates the necessary number of Pods as defined in the ReplicaSet's `replicas` field.
   - The Pods are created according to the template defined in the ReplicaSet.

4. **Pod Lifecycle Management**:
   - The Pods start running on available nodes in the cluster.
   - If any Pods fail or are deleted (due to node failure, manual intervention, etc.), the ReplicaSet controller detects the discrepancy between the desired state and the actual state.

5. **ReplicaSet Ensures Desired State**:
   - The ReplicaSet controller automatically creates new Pods to replace the ones that have failed or been deleted.
   - This ensures that the number of running Pods always matches the desired number of replicas.

### Detailed Example with Sequence

1. **User Creates a Deployment**:
   - Example YAML:
     ```yaml
     apiVersion: apps/v1
     kind: Deployment
     metadata:
       name: example-deployment
     spec:
       replicas: 3
       selector:
         matchLabels:
           app: example
       template:
         metadata:
           labels:
             app: example
         spec:
           containers:
           - name: example-container
             image: nginx:1.14.2
             ports:
             - containerPort: 80
     ```
   - User submits this YAML using `kubectl apply -f deployment.yaml`.

2. **Deployment Controller Processes the Deployment**:
   - The Deployment controller creates a new ReplicaSet with the same template as the Deployment.

3. **ReplicaSet Creates Pods**:
   - The ReplicaSet controller creates 3 Pods as specified in the `replicas` field of the Deployment.

4. **Pods Start Running**:
   - These Pods are scheduled on available nodes and start running the specified container image (nginx:1.14.2).

5. **Pod Failure and Self-Healing**:
   - If one of the Pods crashes or is deleted, the ReplicaSet controller detects that only 2 out of the 3 desired Pods are running.
   - The ReplicaSet controller then creates a new Pod to replace the failed/deleted one, bringing the total back to 3.

### Visualization of the Sequence

1. **User Action**:
   - `kubectl apply -f deployment.yaml`

2. **Deployment Controller Action**:
   - Creates a ReplicaSet based on Deployment specification.

3. **ReplicaSet Controller Action**:
   - Ensures the specified number of Pods (3) are running.
   - Creates Pods based on the Pod template.

4. **Pod Management**:
   - Pods are running and managed by the ReplicaSet.
   - If a Pod fails:
     - ReplicaSet detects the failure.
     - Creates a new Pod to maintain the desired state.

### Summary

- **Deployment**: User creates a Deployment to define the desired state of the application.
- **ReplicaSet**: Created by the Deployment controller to maintain the specified number of Pod replicas.
- **Pods**: Created and managed by the ReplicaSet. If Pods fail, the ReplicaSet ensures they are recreated to match the desired number of replicas.

This sequence ensures that applications remain highly available and resilient to failures, simplifying the management of containerized applications in Kubernetes.

Sure! Here's a step-by-step guide to creating a ReplicaSet in Kubernetes that starts 3 pods, verifying their status, testing self-healing by deleting a pod, and confirming that an additional pod with the same label is terminated:

### Step 1: Create a ReplicaSet Manifest

Create a file named `rs.yml` with the following content:

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-replicaset
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

### Step 2: Apply the Manifest

Apply the `rs.yml` manifest using the `kubectl` command:

```sh
kubectl apply -f rs.yml
```

### Step 3: Get the ReplicaSet Details

Retrieve the details of the ReplicaSet to confirm it is running the desired number of pods:

```sh
kubectl get rs
```

Expected output:

```
NAME               DESIRED   CURRENT   READY   AGE
nginx-replicaset   3         3         3       23s
```

### Step 4: Check the Pods

List the pods to verify they are running:

```sh
kubectl get pods
```

Expected output:

```
NAME                     READY   STATUS    RESTARTS   AGE
nginx-replicaset-7zp2v   1/1     Running   0          35s
nginx-replicaset-q264f   1/1     Running   0          35s
nginx-replicaset-vj42z   1/1     Running   0          35s
```

### Step 5: Test Self-Healing

Delete one of the pods and check if the ReplicaSet replaces it:

```sh
kubectl delete pod nginx-replicaset-7zp2v
kubectl get pods
```

Shortly after deleting, you should see a new pod created by the ReplicaSet to maintain the desired number of replicas.

### Step 6: Add an Additional Pod with the Same Label

Run a new pod with the `app=nginx` label and observe its termination:

```sh
kubectl run nginx-pod --image=nginx --labels="app=nginx"
kubectl get pods
```

The new pod should be terminated almost immediately because the ReplicaSet already ensures 3 pods are running.

### Step 7: Delete the ReplicaSet

Finally, delete the ReplicaSet:

```sh
kubectl delete rs nginx-replicaset
```

This will also terminate all pods managed by the ReplicaSet.

### Notes

- **Naming Convention**: The pods are named after the ReplicaSet followed by a unique ID (e.g., `nginx-replicaset-vj42z`).
- **Self-Healing**: The ReplicaSet ensures that the specified number of replicas are always running. If a pod is deleted, it will be recreated to maintain the desired state.
- **Label Selector**: Any pod created with the same label (`app=nginx`) will be managed by the ReplicaSet, but will be terminated if it exceeds the desired number of replicas.

By following these steps, you can effectively create, manage, and test a ReplicaSet in Kubernetes, ensuring high availability and resilience of your application.


Here's a step-by-step guide to creating a Deployment in Kubernetes that starts 3 pods, verifying their status, testing self-healing by deleting a pod, and confirming that the desired number of pods are maintained:

### Step 1: Create a Deployment Manifest

Create a file named `deployment.yml` with the following content:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

### Step 2: Apply the Deployment

Apply the `deployment.yml` manifest using the `kubectl` command:

```sh
kubectl apply -f deployment.yml
```

### Step 3: Get the Deployment Details

Retrieve the details of the Deployment to confirm it is running the desired number of pods:

```sh
kubectl get deployment
```

Expected output:

```
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           18s
```

### Step 4: Get the ReplicaSet Details

List the ReplicaSets to see the one created by the Deployment:

```sh
kubectl get rs
```

Expected output:

```
NAME                         DESIRED   CURRENT   READY   AGE
nginx-deployment-576c6b7b6   3         3         3       34s
```

### Step 5: Check the Pods

List the pods to verify they are running:

```sh
kubectl get pod
```

Expected output:

```
NAME                               READY   STATUS    RESTARTS   AGE
nginx-deployment-576c6b7b6-b6kgk   1/1     Running   0          46s
nginx-deployment-576c6b7b6-m8ttl   1/1     Running   0          46s
nginx-deployment-576c6b7b6-n9cx4   1/1     Running   0          46s
```

### Step 6: Test Self-Healing

Delete one of the pods and check if the Deployment replaces it:

```sh
kubectl delete pod nginx-deployment-576c6b7b6-b6kgk
kubectl get pods
```

After deletion, you should see a new pod created by the Deployment to maintain the desired number of replicas. The output should show that 3 pods are still running.

### Step 7: Ensure the Pods are Still Up

Confirm that the desired number of pods are still up and running:

```sh
kubectl get pods
```

Expected output:

```
NAME                               READY   STATUS    RESTARTS   AGE
nginx-deployment-576c6b7b6-xxxxx   1/1     Running   0          xx
nginx-deployment-576c6b7b6-xxxxx   1/1     Running   0          xx
nginx-deployment-576c6b7b6-xxxxx   1/1     Running   0          xx
```

### Summary

- **Deployment**: The Deployment ensures that the specified number of pod replicas are running and manages their lifecycle.
- **ReplicaSet**: Created by the Deployment to maintain the desired number of replicas.
- **Pods**: Created and managed by the ReplicaSet. If a pod is deleted, the Deployment will replace it to maintain the desired state.

By following these steps, you can effectively create, manage, and test a Deployment in Kubernetes, ensuring high availability and resilience of your application.
### Understanding the Role of Deployment in Kubernetes

While a ReplicaSet ensures the specified number of pod replicas are running, a Deployment provides a higher-level abstraction for managing applications, offering additional functionality that makes it essential for production environments.

### Why Use a Deployment?

1. **Declarative Updates**:
   - **Deployment**: Allows you to declare the desired state of your application and handles updates in a controlled manner.
   - **ReplicaSet**: Manages pods, but does not provide declarative updates.

2. **Rolling Updates and Rollbacks**:
   - **Deployment**: Supports rolling updates to ensure zero downtime. If an update fails, it can roll back to the previous stable state.
   - **ReplicaSet**: Does not support rolling updates or rollbacks directly.

3. **Revision History**:
   - **Deployment**: Maintains a history of changes to your application. You can review the history and revert to previous versions if necessary.
   - **ReplicaSet**: Does not maintain a revision history.

### Experiment with Deployment and ReplicaSet

1. **Create a Deployment with an Invalid Image**:

   **deployment.yml**:
   ```yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: nginx-deployment
   spec:
     replicas: 3
     selector:
       matchLabels:
         app: nginx
     template:
       metadata:
         labels:
           app: nginx
       spec:
         containers:
         - name: nginx
           image: nginx2:latest
           ports:
           - containerPort: 80
   ```

   Apply the deployment:
   ```sh
   kubectl apply -f deployment.yml
   ```

2. **Check the ReplicaSets and Pods**:

   ```sh
   kubectl get rs
   ```
   Expected output:
   ```
   NAME                          DESIRED   CURRENT   READY   AGE
   nginx-deployment-576c6b7b6    3         3         3       14m
   nginx-deployment-5fbd4799cb   1         1         0       10m
   ```

   ```sh
   kubectl get pods
   ```
   Expected output:
   ```
   NAME                                READY   STATUS             RESTARTS   AGE
   nginx-deployment-576c6b7b6-9nlnq    1/1     Running            0          15m
   nginx-deployment-576c6b7b6-m8ttl    1/1     Running            0          16m
   nginx-deployment-576c6b7b6-n9cx4    1/1     Running            0          16m
   nginx-deployment-5fbd4799cb-fmt4f   0/1     ImagePullBackOff   0          12m
   ```

3. **Rollback to the Previous Deployment**:

   ```sh
   kubectl rollout history deployment/nginx-deployment
   ```

   Undo the last deployment:
   ```sh
   kubectl rollout undo deployment/nginx-deployment
   ```

4. **Create a New Deployment with a Different Image**:

   **deployment.yml**:
   ```yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: nginx-deployment
   spec:
     replicas: 3
     selector:
       matchLabels:
         app: nginx
     template:
       metadata:
         labels:
           app: nginx
       spec:
         containers:
         - name: nginx
           image: postgres:latest
           ports:
           - containerPort: 80
   ```

   Apply the new deployment:
   ```sh
   kubectl apply -f deployment.yml
   ```

5. **Check the ReplicaSets and Pods**:

   ```sh
   kubectl get rs
   ```

   ```sh
   kubectl get pods
   ```

   Check the logs of a pod:
   ```sh
   kubectl logs -f <pod-name>
   ```
   Expected error:
   ```
   Error: Database is uninitialized and superuser password is not specified.
          You must specify POSTGRES_PASSWORD to a non-empty value for the
          superuser. For example, "-e POSTGRES_PASSWORD=password" on "docker run".

          You may also use "POSTGRES_HOST_AUTH_METHOD=trust" to allow all
          connections without a password. This is *not* recommended.

          See PostgreSQL documentation about "trust":
          https://www.postgresql.org/docs/current/auth-trust.html
   ```

6. **Update the Manifest to Pass POSTGRES_PASSWORD**:

   **deployment.yml**:
   ```yaml
   apiVersion: apps/v1
   kind: Deployment
   metadata:
     name: nginx-deployment
   spec:
     replicas: 3
     selector:
       matchLabels:
         app: nginx
     template:
       metadata:
         labels:
           app: nginx
       spec:
         containers:
         - name: nginx
           image: postgres:latest
           ports:
           - containerPort: 80
           env:
           - name: POSTGRES_PASSWORD
             value: "yourpassword"
   ```

   Apply the updated deployment:
   ```sh
   kubectl apply -f deployment.yml
   ```

7. **Check the Pods and Ensure PostgreSQL is Running Correctly**:

   ```sh
   kubectl get pods
   ```

By following these steps, you can see the benefits of using a Deployment over a ReplicaSet. The Deployment manages updates, rollbacks, and ensures a smooth transition between different versions of your application, maintaining high availability and resilience.


### Exposing the Nginx Deployment

To expose the Nginx deployment, you need to create a Service that will provide a stable IP address or DNS name for accessing the application. Kubernetes Services can expose your pods to external traffic, either within the cluster (ClusterIP), on a specified port (NodePort), or externally via a load balancer (LoadBalancer).

Here's a step-by-step guide to expose your Nginx deployment:

### Step 1: Delete Existing Resources

If you have existing resources, delete them first:

```sh
kubectl delete deployment nginx-deployment
```

### Step 2: Create a Deployment Manifest

Create the deployment manifest file `deployment.yml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

Apply the deployment:

```sh
kubectl apply -f deployment.yml
```

### Step 3: Verify Pods

Get the pod details:

```sh
kubectl get pods -o wide
```

Expected output:

```
NAME                               READY   STATUS    RESTARTS   AGE     IP            NODE            NOMINATED NODE   READINESS GATES
nginx-deployment-576c6b7b6-7jrn5   1/1     Running   0          2m19s   10.244.2.19   local-worker2   <none>           <none>
nginx-deployment-576c6b7b6-88fkh   1/1     Running   0          2m22s   10.244.1.13   local-worker    <none>           <none>
nginx-deployment-576c6b7b6-zf8ff   1/1     Running   0          2m25s   10.244.2.18   local-worker2   <none>           <none>
```

### Step 4: Create a Service to Expose the Deployment

Create a Service manifest file `service.yml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer
```

Apply the Service:

```sh
kubectl apply -f service.yml
```

### Step 5: Verify the Service

Check the service details:

```sh
kubectl get svc nginx-service
```

Expected output:

```
NAME            TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
nginx-service   LoadBalancer   10.96.118.218   <pending>     80:30679/TCP   2m
```

- **ClusterIP**: The internal IP address of the service within the cluster.
- **EXTERNAL-IP**: If using a cloud provider, this will eventually be populated with an external IP address. In local environments, this may remain `<pending>`.

### Step 6: Access the Application

- **Cloud Environment**: Use the `EXTERNAL-IP` to access the application.
- **Local Environment**: If using Minikube, you can access the service using Minikube's IP and NodePort.

For Minikube:

1. Get Minikube IP:
   ```sh
   minikube ip
   ```

2. Get NodePort:
   ```sh
   kubectl get svc nginx-service
   ```
   Look for the `NodePort` value (e.g., `30679`).

3. Access the service:
   ```sh
   http://<minikube-ip>:<node-port>
   ```

By following these steps, you can expose your Nginx deployment and access it externally.

### Exposing the Nginx Deployment

To expose the Nginx deployment, you need to create a Service that will provide a stable IP address or DNS name for accessing the application. Kubernetes Services can expose your pods to external traffic, either within the cluster (ClusterIP), on a specified port (NodePort), or externally via a load balancer (LoadBalancer).

Here's a step-by-step guide to expose your Nginx deployment:

### Step 1: Delete Existing Resources

If you have existing resources, delete them first:

```sh
kubectl delete deployment nginx-deployment
```

### Step 2: Create a Deployment Manifest

Create the deployment manifest file `deployment.yml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

Apply the deployment:

```sh
kubectl apply -f deployment.yml
```

### Step 3: Verify Pods

Get the pod details:

```sh
kubectl get pods -o wide
```

Expected output:

```
NAME                               READY   STATUS    RESTARTS   AGE     IP            NODE            NOMINATED NODE   READINESS GATES
nginx-deployment-576c6b7b6-7jrn5   1/1     Running   0          2m19s   10.244.2.19   local-worker2   <none>           <none>
nginx-deployment-576c6b7b6-88fkh   1/1     Running   0          2m22s   10.244.1.13   local-worker    <none>           <none>
nginx-deployment-576c6b7b6-zf8ff   1/1     Running   0          2m25s   10.244.2.18   local-worker2   <none>           <none>
```

### Step 4: Create a Service to Expose the Deployment

Create a Service manifest file `service.yml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer
```

Apply the Service:

```sh
kubectl apply -f service.yml
```

### Step 5: Verify the Service

Check the service details:

```sh
kubectl get svc nginx-service
```

Expected output:

```
NAME            TYPE           CLUSTER-IP      EXTERNAL-IP   PORT(S)        AGE
nginx-service   LoadBalancer   10.96.118.218   <pending>     80:30679/TCP   2m
```

- **ClusterIP**: The internal IP address of the service within the cluster.
- **EXTERNAL-IP**: If using a cloud provider, this will eventually be populated with an external IP address. In local environments, this may remain `<pending>`.

### Step 6: Access the Application

- **Cloud Environment**: Use the `EXTERNAL-IP` to access the application.
- **Local Environment**: If using Minikube, you can access the service using Minikube's IP and NodePort.

For Minikube:

1. Get Minikube IP:
   ```sh
   minikube ip
   ```

2. Get NodePort:
   ```sh
   kubectl get svc nginx-service
   ```
   Look for the `NodePort` value (e.g., `30679`).

3. Access the service:
   ```sh
   http://<minikube-ip>:<node-port>
   ```

By following these steps, you can expose your Nginx deployment and access it externally.


### Kubernetes Services

A Kubernetes Service is an abstraction that allows you to expose an application running on a set of Pods as a network service. This abstraction decouples the logical service from the Pods providing it, allowing for dynamic scaling and seamless updates.

#### Key Concepts

1. **Pod Selector**: Services use labels to select the Pods they target. A label selector identifies a set of Pods based on their labels.
2. **Service Types**:
   - **ClusterIP**: Exposes the Service on an internal IP in the cluster. This is the default ServiceType and is only accessible within the cluster.
   - **NodePort**: Exposes the Service on each Node’s IP at a static port (the NodePort). A ClusterIP Service, to which the NodePort Service routes, is automatically created. You can contact the NodePort Service from outside the cluster by requesting `<NodeIP>:<NodePort>`.
   - **LoadBalancer**: Exposes the Service externally using a cloud provider’s load balancer. NodePort and ClusterIP Services, to which the external load balancer routes, are automatically created.
3. **Endpoints**: Automatically created and updated by Kubernetes when the Pods selected by a Service's selector change.

### Example: Exposing Nginx Deployment Using NodePort

1. **Create Deployment Manifest**

Create a deployment manifest file `deployment.yml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

Apply the deployment:

```sh
kubectl apply -f deployment.yml
```

2. **Create Service Manifest**

Create a Service manifest file `service.yml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30007  # This port can be any valid port within the NodePort range
  type: NodePort
```

3. **Restart the Cluster with Extra Ports Exposed**

Create a Kind configuration file `kind.yml`:

```yaml
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
- role: control-plane
  extraPortMappings:
  - containerPort: 30007
    hostPort: 30007
- role: worker
- role: worker
```

Create the cluster with the configuration:

```sh
kind create cluster --config kind.yml
```

4. **Re-apply the Deployment and Service**

Re-apply the deployment and the service:

```sh
kubectl apply -f deployment.yml
kubectl apply -f service.yml
```

5. **Verify the Setup**

Get the service details:

```sh
kubectl get svc nginx-service
```

Expected output:

```
NAME            TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)        AGE
nginx-service   NodePort   10.96.0.1      <none>        80:30007/TCP   2m
```

Get the pods details:

```sh
kubectl get pods -o wide
```

Expected output:

```
NAME                               READY   STATUS    RESTARTS   AGE     IP            NODE            NOMINATED NODE   READINESS GATES
nginx-deployment-576c6b7b6-7jrn5   1/1     Running   0          2m19s   10.244.2.19   local-worker2   <none>           <none>
nginx-deployment-576c6b7b6-88fkh   1/1     Running   0          2m22s   10.244.1.13   local-worker    <none>           <none>
nginx-deployment-576c6b7b6-zf8ff   1/1     Running   0          2m25s   10.244.2.18   local-worker2   <none>           <none>
```

6. **Access the Application**

Visit `http://localhost:30007` in your browser. You should see the default Nginx welcome page.

### Summary

- **ClusterIP**: Internal access within the cluster.
- **NodePort**: External access using `<NodeIP>:<NodePort>`.
- **LoadBalancer**: External access using a cloud provider’s load balancer.

By following these steps, you can expose your Nginx deployment using a NodePort service, making it accessible externally on the specified port.

### Exposing a Kubernetes Service Using a LoadBalancer on Vultr

To expose a Kubernetes service to external clients using a LoadBalancer, you can follow these steps:

#### Step 1: Create a Kubernetes Cluster on Vultr

Follow the instructions provided by Vultr to set up a Kubernetes cluster. Once your cluster is ready and you have `kubectl` configured to interact with it, proceed with the following steps.

#### Step 2: Create the Deployment

Create a deployment manifest file `deployment.yml`:

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:latest
        ports:
        - containerPort: 80
```

Apply the deployment:

```sh
kubectl apply -f deployment.yml
```

#### Step 3: Create the LoadBalancer Service

Create a service manifest file `service-lb.yml`:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-service
spec:
  selector:
    app: nginx
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: LoadBalancer
```

Apply the service:

```sh
kubectl apply -f service-lb.yml
```

#### Step 4: Verify the Service

Check the status of the service to see if an external IP address has been assigned:

```sh
kubectl get svc nginx-service
```

Expected output:

```
NAME            TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE
nginx-service   LoadBalancer   10.96.118.218    <pending>     80:30679/TCP   2m
```

It may take a few moments for the external IP to be assigned. Once assigned, you should see something like this:

```
NAME            TYPE           CLUSTER-IP       EXTERNAL-IP     PORT(S)        AGE
nginx-service   LoadBalancer   10.96.118.218    192.0.2.1       80:30679/TCP   5m
```

#### Step 5: Access the Application

Visit the `EXTERNAL-IP` in your browser or use `curl` to verify access:

```sh
curl http://192.0.2.1
```

You should see the default Nginx welcome page.

### Summary

Using the LoadBalancer service type in Kubernetes, you can expose your applications to external clients. This type leverages your cloud provider’s load balancing capabilities to route traffic from an external IP to your Kubernetes service. This is particularly useful for making applications accessible outside the cluster with minimal configuration.
